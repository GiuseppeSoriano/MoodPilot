{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoCapture\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow(\"Camera\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FER\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\giova\\anaconda3\\envs\\IA_Project\\Lib\\site-packages\\fer\\__init__.py:27\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/python3\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# SOFTWARE.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Video\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FER\n\u001b[0;32m     30\u001b[0m log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\giova\\anaconda3\\envs\\IA_Project\\Lib\\site-packages\\fer\\classes.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, Union\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "from fer import FER\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = FER(mtcnn=True)  # Use MTCNN for face detection\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect emotions\n",
    "    emotions = detector.detect_emotions(frame)\n",
    "    for emotion in emotions:\n",
    "        box = emotion['box']\n",
    "        dominant_emotion = emotion['emotions']\n",
    "        cv2.rectangle(frame, (box[0], box[1]), (box[0] + box[2], box[1] + box[3]), (255, 0, 0), 2)\n",
    "        cv2.putText(frame, max(dominant_emotion, key=dominant_emotion.get), (box[0], box[1] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Emotion Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        # Analyze emotions in the current frame\n",
    "        analysis = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "        dominant_emotion = analysis['dominant_emotion']\n",
    "\n",
    "        # Display emotion on the video feed\n",
    "        cv2.putText(frame, dominant_emotion, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "    cv2.imshow(\"Emotion Detection\", frame)\n",
    "\n",
    "    # Exit on 'q' key or if window is closed\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q') or cv2.getWindowProperty(\"Emotion Detection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FER\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the FER detector\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giova\\anaconda3\\envs\\IA_Project\\Lib\\site-packages\\fer\\__init__.py:27\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/python3\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# SOFTWARE.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Video\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FER\n\u001b[0;32m     30\u001b[0m log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\giova\\anaconda3\\envs\\IA_Project\\Lib\\site-packages\\fer\\classes.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, Union\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "from fer import FER\n",
    "import cv2\n",
    "\n",
    "# Initialize the FER detector\n",
    "detector = FER(mtcnn=True)  # Enable MTCNN for more accurate face detection\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect emotions and faces\n",
    "    emotions = detector.detect_emotions(frame)\n",
    "\n",
    "    for emotion in emotions:\n",
    "        box = emotion['box']  # Bounding box coordinates (x, y, width, height)\n",
    "        dominant_emotion = max(emotion['emotions'], key=emotion['emotions'].get)  # Most probable emotion\n",
    "\n",
    "        # Draw bounding box\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # Add emotion label\n",
    "        cv2.putText(frame, dominant_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    # Display the video feed\n",
    "    cv2.imshow(\"Emotion Detection\", frame)\n",
    "\n",
    "    # Exit on 'q' key or if window is closed\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q') or cv2.getWindowProperty(\"Emotion Detection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the output confirms that DeepFace returns a list with a dictionary for each detected face. Here's how you can update your code to handle the returned data correctly and display the dominant emotion on the overlay:\n",
    "\n",
    "Updated Code for DeepFace Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "import cv2\n",
    "\n",
    "# Load OpenCV's pre-trained Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = frame[y:y + h, x:x + w]  # Extract the face region\n",
    "\n",
    "        try:\n",
    "            # Ensure the face ROI is valid before analysis\n",
    "            if face_roi.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Analyze emotions for the detected face\n",
    "            analysis = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)\n",
    "            if isinstance(analysis, list):  # If multiple faces, process the first one\n",
    "                analysis = analysis[0]\n",
    "\n",
    "            # Extract the dominant emotion correctly\n",
    "            dominant_emotion = analysis['dominant_emotion']\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Add emotion label\n",
    "            cv2.putText(frame, dominant_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing face: {e}\")\n",
    "\n",
    "    # Display the video feed\n",
    "    cv2.imshow(\"Emotion Detection\", frame)\n",
    "\n",
    "    # Exit on 'q' key or if window is closed\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q') or cv2.getWindowProperty(\"Emotion Detection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using a PyTorch Model (Custom Model)\n",
    "If you want to experiment with a pre-trained PyTorch-based model (like ResNet), you can implement your custom FER pipeline. This involves:\n",
    "\n",
    "Using MTCNN for face detection.\n",
    "Passing the cropped face to a pre-trained PyTorch model for emotion classification.\n",
    "Setup PyTorch Model\n",
    "For simplicity, you can use a pre-trained FER model or fine-tuned ResNet.\n",
    "\n",
    "Code for PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Initialize MTCNN for face detection\n",
    "mtcnn = MTCNN(keep_all=True, device='cpu')\n",
    "\n",
    "# Load a pre-trained ResNet for emotion classification\n",
    "# Replace with your fine-tuned FER model if available\n",
    "model = resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 7)  # Assuming 7 emotion classes\n",
    "model.eval()\n",
    "\n",
    "# Define emotion labels\n",
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "# Preprocessing pipeline for PyTorch model\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect faces using MTCNN\n",
    "    boxes, _ = mtcnn.detect(frame)\n",
    "\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            face = frame[y1:y2, x1:x2]  # Crop the face region\n",
    "\n",
    "            # Ensure the face region is valid\n",
    "            if face.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Preprocess the face for the model\n",
    "            face_tensor = transform(face).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "            # Predict emotion\n",
    "            with torch.no_grad():\n",
    "                outputs = model(face_tensor)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                emotion = emotion_labels[predicted.item()]\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Add emotion label\n",
    "            cv2.putText(frame, emotion, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the video feed\n",
    "    cv2.imshow(\"PyTorch Emotion Detection\", frame)\n",
    "\n",
    "    # Exit on 'q' key or if window is closed\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q') or cv2.getWindowProperty(\"PyTorch Emotion Detection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained_ckpt does not exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pretrained_ckpt..: 100%|██████████| 552M/552M [02:14<00:00, 4.11MiB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploy.prototxt.txt does not exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading deploy.prototxt.txt..: 100%|██████████| 28.1k/28.1k [00:00<00:00, 4.68MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res10_300x300_ssd_iter_140000.caffemodel does not exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading res10_300x300_ssd_iter_140000.caffemodel..: 100%|██████████| 10.7M/10.7M [00:01<00:00, 6.85MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n",
      "num faces: 1\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/phamquiluan/ResidualMaskingNetwork\n",
    "from rmn import RMN\n",
    "m = RMN()\n",
    "m.video_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, **DeepFace** can handle face detection internally, so you don't necessarily need to use an external face detection model like OpenCV's Haar cascade. When you call `DeepFace.analyze()`, it will automatically detect faces if none are provided. This is very convenient since it simplifies the process by eliminating the need for manual face detection.\n",
    "\n",
    "Here's how you can modify your code to rely purely on **DeepFace** for both face detection and emotion analysis:\n",
    "\n",
    "### **Updated Code Using DeepFace for Face Detection and Emotion Analysis**:\n",
    "\n",
    "\n",
    "\n",
    "### **Changes in the Code**:\n",
    "\n",
    "1. **Automatic Face Detection**:\n",
    "   - The `DeepFace.analyze()` function automatically detects faces in the provided image (in this case, from your webcam feed). You no longer need to manually use OpenCV's Haar Cascade for face detection.\n",
    "\n",
    "2. **Emotion Analysis**:\n",
    "   - The `actions=['emotion']` argument instructs DeepFace to perform emotion detection on the detected faces.\n",
    "\n",
    "3. **Handling Multiple Faces**:\n",
    "   - DeepFace will return a list of analyses for each face detected. The loop processes each face and draws a bounding box and emotion label.\n",
    "\n",
    "4. **`enforce_detection=False`**:\n",
    "   - This argument allows DeepFace to process the image even if no face is detected. If no faces are found, the code won't raise an error.\n",
    "\n",
    "### **How DeepFace Handles Face Detection**:\n",
    "- **DeepFace** uses a variety of face detection models (like `opencv`, `mtcnn`, `dlib`, or `retinaface`) internally depending on the configuration or availability. By default, DeepFace automatically chooses the appropriate model based on the environment and the requirements.\n",
    "\n",
    "### **Running the Code**:\n",
    "When you run this code, DeepFace will handle everything:\n",
    "- **Face detection** (no need for `cv2.CascadeClassifier`)\n",
    "- **Emotion detection** for each face detected\n",
    "- Display the webcam feed with bounding boxes and emotion labels in real time.\n",
    "\n",
    "This version is simpler and avoids the need to integrate external face detection models manually. Let me know if you encounter any issues or need further modifications!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error you're encountering — **\"too many values to unpack (expected 4)\"** — occurs when trying to unpack the face detection results incorrectly. In the DeepFace output, the face region is returned as a dictionary, and you're trying to unpack it as if it were a tuple (which it isn't).\n",
    "\n",
    "This issue happens when you try to access the face region in an incorrect format.\n",
    "\n",
    "### **Solution**:\n",
    "In DeepFace's output, the **face region** is a dictionary with the keys `x`, `y`, `w`, and `h` representing the coordinates and size of the detected face. Instead of trying to unpack it directly into four variables, you should access the values using their respective keys.\n",
    "\n",
    "Here's the corrected code:\n",
    "\n",
    "### **Corrected Code**:\n",
    "\n",
    "\n",
    "### **Key Changes**:\n",
    "1. **Accessing the face region correctly**: \n",
    "   - The face region is stored as a dictionary with keys `'x'`, `'y'`, `'w'`, and `'h'`. \n",
    "   - Instead of unpacking it like a tuple, we access the values directly using `face_region['x']`, `face_region['y']`, `face_region['w']`, and `face_region['h']`.\n",
    "\n",
    "This should fix the \"too many values to unpack\" error you're seeing. \n",
    "\n",
    "### **Explanation**:\n",
    "- **DeepFace Output Structure**: The result of `DeepFace.analyze()` contains a list of dictionaries (one per detected face). Each dictionary contains keys like `'dominant_emotion'`, `'region'`, and other face analysis information.\n",
    "- **Face Region**: The `'region'` key contains another dictionary with the face's bounding box coordinates, and we access those coordinates individually instead of trying to unpack them all at once.\n",
    "\n",
    "Let me know if this resolves the issue or if you encounter any other problems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\giova\\anaconda3\\envs\\IA_Project\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import cv2\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        # Analyze the image with DeepFace (detect faces and emotions internally)\n",
    "        analysis = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "        \n",
    "        # Loop through all detected faces (if multiple faces are detected)\n",
    "        for face_analysis in analysis:\n",
    "            # Get the dominant emotion\n",
    "            dominant_emotion = face_analysis['dominant_emotion']\n",
    "\n",
    "            # Get the region of the detected face (as a dictionary, not a tuple)\n",
    "            face_region = face_analysis['region']\n",
    "            x, y, w, h = face_region['x'], face_region['y'], face_region['w'], face_region['h']\n",
    "\n",
    "            # Draw bounding box around the face\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Add the emotion label\n",
    "            cv2.putText(frame, dominant_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing face: {e}\")\n",
    "\n",
    "    # Display the video feed with detected emotions\n",
    "    cv2.imshow(\"Emotion Detection\", frame)\n",
    "\n",
    "    # Exit on 'q' key or if the window is closed\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q') or cv2.getWindowProperty(\"Emotion Detection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s how you can integrate the **\"trpakov/vit-face-expression\"** model with OpenCV to perform real-time emotion detection using your webcam feed. The process involves loading the pre-trained model and image processor from Hugging Face, detecting faces in the video stream using OpenCV, and analyzing the emotions using the model.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Explanation**:\n",
    "1. **Model and Processor**:\n",
    "   - The model (`AutoModelForImageClassification`) and processor (`AutoImageProcessor`) are loaded from Hugging Face. \n",
    "   - The processor handles image preprocessing like resizing, normalization, and tensor conversion.\n",
    "   \n",
    "2. **Face Detection**:\n",
    "   - OpenCV's Haar cascade is used to detect faces in the video frame.\n",
    "   - Each detected face is cropped from the frame (`face_roi`) for emotion classification.\n",
    "\n",
    "3. **Emotion Analysis**:\n",
    "   - The face is converted into a PIL image and passed through the processor for preprocessing.\n",
    "   - The preprocessed image is fed into the model to get the logits.\n",
    "   - Softmax is applied to convert logits to probabilities, and the class with the highest probability is selected as the predicted emotion.\n",
    "\n",
    "4. **Visualization**:\n",
    "   - Bounding boxes are drawn around the detected faces.\n",
    "   - The predicted emotion is displayed as a label near the bounding box.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "\n",
    "# Load model and processor\n",
    "processor = AutoImageProcessor.from_pretrained(\"trpakov/vit-face-expression\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"trpakov/vit-face-expression\")\n",
    "\n",
    "# Load OpenCV's Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract face ROI\n",
    "        face_roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "        try:\n",
    "            # Convert to PIL Image and preprocess\n",
    "            face_pil = Image.fromarray(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))\n",
    "            inputs = processor(face_pil, return_tensors=\"pt\")\n",
    "\n",
    "            # Run inference\n",
    "            outputs = model(**inputs)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "            predicted_class = probs.argmax().item()\n",
    "            predicted_label = model.config.id2label[predicted_class]\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, predicted_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing face: {e}\")\n",
    "\n",
    "    # Display the video feed\n",
    "    cv2.imshow(\"Emotion Detection\", frame)\n",
    "\n",
    "    # Exit on 'q' key or if the window is closed\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q') or cv2.getWindowProperty(\"Emotion Detection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it's absolutely possible to display the current **frames per second (FPS)** on the preview window. To calculate FPS in OpenCV, you can use a simple approach by measuring the time taken to process each frame. By keeping track of the time before and after processing each frame, you can calculate the FPS and display it on the video stream.\n",
    "\n",
    "Here’s how you can modify your code to calculate and display the FPS:\n",
    "\n",
    "### **Updated Code with FPS Display**:\n",
    "\n",
    "---\n",
    "\n",
    "### **Changes for FPS Calculation**:\n",
    "1. **Track Time for FPS**:\n",
    "   - We use `time.time()` to get the current time before and after each frame is processed.\n",
    "   - The FPS is calculated as the inverse of the difference between the current time and the previous time (`1 / (curr_time - prev_time)`).\n",
    "\n",
    "2. **Display FPS**:\n",
    "   - We use `cv2.putText()` to draw the FPS value on the frame. The text is placed in the top-left corner of the window (`(10, 30)`).\n",
    "\n",
    "3. **Frame Processing**:\n",
    "   - For each frame, we calculate the FPS and update the `prev_time` for the next frame.\n",
    "\n",
    "---\n",
    "\n",
    "### **Explanation**:\n",
    "- **FPS Calculation**: \n",
    "  - FPS is calculated based on the time elapsed between frames. The faster the frames are processed, the higher the FPS will be. This gives you a real-time indication of how many frames are processed per second.\n",
    "  \n",
    "- **Displaying FPS**: \n",
    "  - The FPS is displayed in the top-left corner of the window. You can change the position and style of the FPS text if needed.\n",
    "\n",
    "---\n",
    "\n",
    "### **Result**:\n",
    "When you run the program, you'll see the FPS in the top-left corner of the preview window, alongside the bounding boxes and emotion labels for detected faces.\n",
    "\n",
    "Let me know if you need further assistance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giova\\anaconda3\\envs\\IA_Project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Load model and processor\n",
    "processor = AutoImageProcessor.from_pretrained(\"trpakov/vit-face-expression\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"trpakov/vit-face-expression\")\n",
    "\n",
    "# Load OpenCV's Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# FPS calculation variables\n",
    "prev_time = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Get the current time\n",
    "    curr_time = time.time()\n",
    "\n",
    "    # Calculate FPS (frames per second)\n",
    "    fps = 1 / (curr_time - prev_time)\n",
    "    prev_time = curr_time\n",
    "\n",
    "    # Convert frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract face ROI\n",
    "        face_roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "        try:\n",
    "            # Convert to PIL Image and preprocess\n",
    "            face_pil = Image.fromarray(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))\n",
    "            inputs = processor(face_pil, return_tensors=\"pt\")\n",
    "\n",
    "            # Run inference\n",
    "            outputs = model(**inputs)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "            predicted_class = probs.argmax().item()\n",
    "            predicted_label = model.config.id2label[predicted_class]\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, predicted_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing face: {e}\")\n",
    "\n",
    "    # Display FPS on the frame\n",
    "    cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the video feed with detected emotions\n",
    "    cv2.imshow(\"Emotion Detection\", frame)\n",
    "\n",
    "    # Exit on 'q' key or if the window is closed\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q') or cv2.getWindowProperty(\"Emotion Detection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
