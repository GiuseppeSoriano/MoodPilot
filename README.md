![MoodPilot](MoodPilot.png)

MoodPilot: Combines "mood" and "pilot" to reflect an emphasis on emotional monitoring for improved guidance.


## Project Overview

This project aims to develop an evaluation system for assessing the mood of passengers in self-driving cars or Uber rides. The system will evaluate the driving capacity of the driver during the trip and determine if the passenger(s) experienced any fear or discomfort. Additionally, passengers will be able to rate their trip experience and provide additional comments if they wish.

## Features

- **Mood Detection**: Analyze passengers' facial expressions and physiological signals to determine their mood during the trip.
- **Driver Evaluation**: Assess the driving performance based on passenger feedback and mood analysis.
- **Trip Rating**: Allow passengers to rate their trip experience at the end of the journey and provide optional comments.
- **Data Collection**: Collect and store data for further analysis and improvement of the system.

## Technologies Used

- **Machine Learning**: For mood detection and analysis.
- **Computer Vision**: To analyze facial expressions.
- **Sensors**: To capture physiological signals.
- **Backend**: For data storage and processing.
- **Frontend**: For user interface and trip rating.

## Installation

1. Clone the repository:
    ```bash
    git clone https://github.com/yourusername/passenger-mood-evaluation.git
    ```
2. Navigate to the project directory:
    ```bash
    cd passenger-mood-evaluation
    ```
    ```

## Contributing

We welcome contributions to improve the system. Please follow these steps to contribute:

1. Fork the repository.
2. Create a new branch for your feature or bugfix.
3. Commit your changes and push the branch to your fork.
4. Create a pull request with a detailed description of your changes.

## Palette
Palette by [coolors.co](https://coolors.co/palette/f9dbbd-fca17d-da627d-9a348e-0d0628)

![Palette](Palette.png)

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

Ecco una tabella comparativa che evidenzia la presenza o l'assenza di specifiche caratteristiche nel sistema proposto basato sul riconoscimento delle emozioni facciali (FER), nei servizi offerti da Uber e nei taxi tradizionali:

| **Caratteristica**                          | **Sistema Proposto (FER)** | **Uber** | **Taxi Tradizionali** |
|---------------------------------------------|----------------------------|----------|-----------------------|
| **Valutazione in tempo reale**              | Presente                   | Assente  | Assente               |
| **Feedback oggettivo basato su dati biometrici** | Presente                   | Assente  | Assente               |
| **Dettaglio delle valutazioni**             | Presente                   | Assente  | Assente               |
| **Feedback non intrusivo**                  | Presente                   | Assente  | Assente               |
| **Monitoraggio continuo della qualit√†**     | Presente                   | Assente  | Assente               |
| **Personalizzazione del servizio**          | Presente                   | Presente | Assente               |
| **Formazione dei conducenti basata su feedback** | Presente                   | Presente | Assente               |
| **Gestione della privacy e del consenso**   | Necessaria(FEDERATED LEARNING)                 | Presente | Non applicabile       |
| **Implementazione tecnologica avanzata**    | Necessaria(FER)                 | Presente | Assente               |
<!-- | **Accettazione da parte dei passeggeri**    | Da valutare                | Presente | Presente              | -->

Questa tabella evidenzia come il sistema proposto integri diverse caratteristiche innovative rispetto alle soluzioni attuali offerte da Uber e dai taxi tradizionali, pur richiedendo attenzione particolare alla gestione della privacy e all'implementazione tecnologica. 